# 처리율 제한 장치의 설계

- 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치입니다.
- 해당 장치를 사용하여 특정 기간내에 전송되는 클라이언트의 요청 횟수를 제한할 수 있습니다.

#### 처리율 제한 장치가 필요한 이유

- Dos 공격에 의한 자원 고갈 방지
- 서버 과부화를 방지합니다.
- 바용을 절감합니다.

<br>

## 1 단계. 처리율 제한 장치에 대한 요구사항 이해

- 어떤 키를 사용하여 API 호출을 제어해야 하는가?(Ip주소, 사용자 아이디 등)
- 낮은 응답시간 지원
- 적은 메모리 사용
- 예외 처리
- 처리율 제한 장치에 장애가 발생하더라도 전체적인 시스템에 영향을 미치면 안된다.

<br>

## 2 단계. 계략적인 설계안 제시 및 동의 구하기

### 처리율 제한 장치를 어디에 둘 것인가?

#### 클라이언트 측에 두는 경우

- 클라이언트측에 처리율 제한 장치를 둘 수 있지만 클라이언트의 요청은 쉽게 위변조가 가능하기 때문에 적절하지 않습니다.

#### 서버 측에 두는 경우

- 모놀리식 구조에서 처리율 제한 장치를 개발해야한다면 서버측에 처리율 제한 장치를 둘 수 있지만 마이크로 서비스 구조라면 서버측에 둬야할까? 고민을 해봐야할거 같습니다.

<img width="1032" alt="스크린샷 2024-06-16 오후 1 31 39" src="https://github.com/kdg0209/realizers/assets/80187200/71f44f1f-0170-45aa-8bb2-2040dda7132d">

<br>

#### 미들웨어 측에 두는 경우

- 처리율 제한 장치를 API 게이트 웨이를 구현한 애플리케이션에 둘 수 있습니다.
- API 게이트 웨이의 역할은 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원합니다.

<img width="1032" alt="스크린샷 2024-06-16 오후 1 42 52" src="https://github.com/kdg0209/realizers/assets/80187200/c7d3b400-5607-4fed-81c9-08f6581f4893">

<br><br>

### 처리율 제한 장치를 구현하는 알고리즘

#### 토큰 버킷 알고리즘

🚗 동작 원리

- 토큰 버킷은 지정된 용량을 갖는 컨테이너입니다. 해당 버킷에는 설정된 양의 토큰이 주기적으로 채워집니다. 만약 버킷이 꽉 찬다면 추가적인 토큰은 버려집니다.
- 사용자의 요청이 들어오면 버킷에서 하나의 토큰을 소모하게 됩니다. 만약 충분한 토큰이 없다면 해당 요청은 버려집니다.
- 버킷 크기란 버킷에 허용되는 최대 토큰의 수입니다.
- 리필 비율이란 매초 또는 매분마다 버킷에 채워질 토큰의 수입니다.

💡 장점

- 구현이 쉽습니다. 그리고 AWS에서 기본적으로 제공하는 처리율 제한 장치입니다.
- IP 주소별로 처리율을 제한한다면 IP 주소마다 버킷을 하나씩 할당하여 구현할 수 있습니다.

🤔 단점

- 요구사항이 많아지면 해당 방법으로는 제한이 있습니다.(사용자별 등)
- 버킷 크기와 리필 비율이라는 인자로 적절하게 튜닝하기 어렵습니다.

<img width="1032" alt="스크린샷 2024-06-16 오후 2 21 56" src="https://github.com/kdg0209/realizers/assets/80187200/139046ab-fec8-4c62-861f-8dd57efc6229">

<br><br>

#### 누출 버킷 알고리즘

🚗 동작 원리

- 요청이 오면 큐(대기열)가 가득 차 있는지 확인합니다.
- 대기열이 가득 차 있지 않으면 대기열의 끝에 요청을 추가합니다.
- 대기열이 가득 차 있다면 요청을 버립니다.
- 정기적으로 대기열의 요청을 가져와 처리합니다.

💡 장점

- 큐의 크기가 제한되어 있어 메모리를 효율적으로 사용할 수 있습니다.
- 고정된 처리율을 가지고 있어 안정적은 출력이 필요한 작업에 적절합니다.

🤔 단점

- 스파이크 트래픽이 발생하는 상황에서는 비교적 오래된 요청은 대기열에 쌓이게 되고, 나머지 요청은 버려집니다.
- 버킷 크기와 유출 속도 두 개의 인자를 가지고 있는데 이것만으로 상세한 튜닝을 하기 어렵습니다.

<img width="1032" alt="스크린샷 2024-06-16 오후 2 36 20" src="https://github.com/kdg0209/realizers/assets/80187200/dc747ea0-32db-4eeb-b352-92616282c507">

<br><br>

#### 고정 윈도 카운터 알고리즘

🚗 동작 원리

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙입니다.
- 요청이 들어오면 해당 타임라인의 카운터를 1 증가시킵니다.
- 카운터의 값이 임계치에 도달하면 새로운 요청은 버려집니다.

💡 장점

- 이해하기 쉽습니다.
- 윈도(타임라인)가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합합니다.

🤔 단점

- 윈도(타임라인) 경계 부근에 일시적으로 많은 트래픽이 몰리는 경우 기대했던 시스템의 처리 한도보다 더 많은 양의 요청을 처리할 수 있게됩니다.

<img width="1032" alt="스크린샷 2024-06-16 오후 2 52 26" src="https://github.com/kdg0209/realizers/assets/80187200/9ede7d0c-7c06-4390-8983-ca0780c33686">

<br><br>

🧐 문제가 발생하는 상황

- 아래는 1분당 3개의 요청을 처리할 수 있는 상황입니다.
- 이때 1시 04분에는 2개의 요청이 들어왔고, 1시 05분에는 3개의 요청이 들어왔습니다. 근데 타임라인은 1시 04분 30초를 본다면 이때 기준으로 본다면 5개의 요청을 처리함을 알 수 있습니다. 그렇기 때문에 임계치보다 높은 처리를 하게되는 상황이 발생하게 됩니다.

<img width="1032" alt="스크린샷 2024-06-16 오후 2 58 45" src="https://github.com/kdg0209/realizers/assets/80187200/65874c26-d65a-4836-9a0a-b606c4150de1">

<br><br>

#### Sliding Window Log 알고리즘

❓ 설명

- 고정 윈도 카운터 알고리즘은 타임라인 경계에 트래픽이 몰리는 경우 시스템에 설정된 임계치보다 더 많은 요청을 처리하게 되는 문제가 있는데, 이동 윈도 로깅 알고리즘을 통해 해결할 수 있습니다.

🚗 동작 원리

- 요청의 타임스탬프를 추적합니다. 타임스탬프는 보통 레디스의 sorted set 자료 구조를 사용하여 저장합니다.
- 새로운 요청이 오면 기존 타임스탬프는 제거하고, 새로운 요청을 레디스에 저장합니다.
- 레디스에 저장된 요청을 보고 임계치보다 작거나 같다면 요청을 처리하고 그렇지 않다면 요청을 버립니다.
  - 요청이 1:00:00에 도착했을 때 로그는 비어있으므로 해당 요청은 처리됩니다.
  - 새로운 요청이 1:00:30에 도착했을 때 로그에 추가되며 임계치는 2이므로 처리됩니다.
  - 새로운 요청이 1:00:50에 도착했을 때 로그에 우선 추가되며, 임계치보다 크기 때문에 처리되지 않습니다.
  - 새로운 요청이 1시:01:40에 도착했을 때 로그에 추가되며, 새로운 요청이 01:01:40에 들어왔기 때문에 1:00:40 이전의 로그는 만료된거기 때문에 삭제합니다. 삭제한 뒤 해당 요청을 로그에 작성합니다. 이후 로그는 2개이고 임계치는 2이므로 해당 요청을 처리합니다.

💡 장점

- 해당 알고리즘은 요청의 시간으로 처리율을 제한하기 때문에 고정 윈도 카운터 알고리즘보다 정교하게 동작합니다.

🤔 단점

- 레디스에 모든 요청의 타임스탬프를 저장해야히기 때문에 메모리를 추가적으로 사용하게 됩니다.

<img width="1033" alt="스크린샷 2024-06-16 오후 3 25 45" src="https://github.com/kdg0209/realizers/assets/80187200/f11c7b39-d637-4fea-ac53-15ae3223bc80">

<br><br>

#### Sliding Window Counter 알고리즘

❓ 설명

- 고정 윈도 카운터 알고리즘과 Sliding Window Log 알고리즘을 결합한 것입니다.

🚗 동작 원리

- 임계치가 분당 7이고, 이전 1분동안 8개의 요청이, 그리고 현재 1분동안 2개의 요청이 왔다고 가정합니다.
- 현재 1분의 30% 시점에 도착한 새 요청의 경우 현재 윈도에 몇개의 요청이 온것으로 보고 요청을 처리할까요?
- 공식
  - 현재 1분간의 요청 수 + 직전 1분간의 요청 수 X 이동 윈도와 직전 1분이 겹치는 비율
  - 2 + 8 X 70% = 6.2개입니다. 반올림해서 쓸수도 있고 내림하여 쓸 수도 있는데, 예시에서는 내림하여 6으로 사용합니다. 그럼 새로운 요청이 들어온다면 해당 요청은 처리될 수 있습니다. 하지만 그 이후의 요청은 처리할 수 없게 됩니다.

💡 장점

- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽도 대응할 수 있습니다.
- 메모리 효율이 좋습니다.

🤔 단점

- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 느슨할 수 있지만 클라우드플레어에서 실행했던 실험에 따르면 40억개의 요청 가운데 버려진 요청은 0.003%에 불과하다고 합니다.

<img width="1032" alt="스크린샷 2024-06-16 오후 3 45 12" src="https://github.com/kdg0209/realizers/assets/80187200/8f7f7a19-8a9d-442b-8fed-68d9a2512a6c">

<br><br>

## 3 단계. 상세 설계

### 무엇을 고민해야 하는가?

#### 처리율 한도 초과 트래픽의 처리

- 요청에 제한이 걸리면 사용자에게 바로 429응답을 보냘 수도 있지만 경우에 따라서 해당 요청을 DLQ에 보관하여 나중에 처리될 수 있도록 할 수 있습니다. 그럼 사용자의 요청은 잠시뒤에 처리하게 됩니다.

#### 처리율 제한 장치가 사용하는 HTTP 헤더

- 클라이언트는 자신이 처리율 제한에 걸렸다는 것을 어떻게 알 수 있을까? 답은 HTTP 응답 헤더를 확인할 수 있습니다.
  - X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수
  - X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
  - X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야하는지 알림
 
#### 분산 환경에서 고려할 점

- 경쟁 조건 및 동기화
- 성능 최적화
- 모니터링 (적절한 알고리즘을 사용하고 있는가? 처리율 제한이 효과적인가?)

<br><br>

## 4 단계. 마무리

- 다음과 같은 부분도 고려할 수 있으면 더욱 좋습니다.

#### 경성 또는 연성 처리율 제한

- 경성 처리율 제한: 요청의 개수는 임계치를 절대 넘을 수 없습니다.
- 연성 처리율 제한: 요청의 개수는 잠시 동안 임계치를 넘을 수 있습니다.

#### 다양한 계층에서의 처리율 제한

- 애플리케이션을 구축하여 처리율 제한을 만드는 것은 OSI 7번 계층에서 수행되지만 Iptables를 사용하면 3번 계층에서도 가능합니다.

#### 처리율 제한을 회피하는 방법(클라이언트를 어떻게 설계해야 최선일까?)

- 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄입니다.
- 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 많은 API를 요청하지 않도록합니다.
- 재시도 로직을 구현할 때 충분한 백 오프 시간을 둡니다.
- 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황을 우아하게 복구할 수 있도록 합니다.

#### 참고

- https://medium.com/geekculture/system-design-design-a-rate-limiter-81d200c9d392
- https://github.com/Salah856/System-Design/blob/main/Design%20Rate%20Limiter.md
- https://cloudxlab.com/blog/system-design-how-to-design-a-rate-limiter/

