# 카프카 컨슈머

<hr>

## Consumer의 구조

- Kafka Consumer Client는 크게 Fetcher, ConsumerNetworkClient, SubscriptionState, ConsumerCoordinator, HeartBeatThread로 구성되어 있습니다.
- Kafka Consumer가 처음 subscribe할 때 Fetcher, ConsumerNetworkClient, SubscriptionState, ConsumerCoordinator가 생성됩니다.
- Kafka Consumer가 처음 poll할 때 ConsumerCoordinator에 의해 HeartBeatThread가 생성됩니다.

<img width="1026" alt="스크린샷 2024-02-12 오후 3 02 16" src="https://github.com/kdg0209/realizers/assets/80187200/3f1eba80-b910-4be9-a1c3-8e64e3965603">

<br>

#### Fetcher의 역할

- Consumer는 poll 메서드를 통해 브로커로부터 레코드를 가져올 수 있습니다.
- Fetcher는 내부에 Linked Queue를 가지고 있는데, 우선 해당 Queue로부터 레코드를 가져오게 되며, 이 Queue가 비어있는 경우 ConsumerNetworkClient에게 브로커에게 레코드 요청을 보내게 됩니다.

#### ConsumerNetworkClient의 역할

- ConsumerNetworkClient는 비동기로 동작하며, 브로커에게 레코드를 받아와 Fetcher의 Linked Queue에 레코드를 채워주게됩니다.

#### SubscriptionState의 역할

- SubscriptionState는 현재 Consumer가 구독하고 있는 토픽, 파티션, 오프셋 정보를 관리합니다.

#### ConsumerCoordinator의 역할

- ConsumerCoordinator는 Consumer 리밸런싱, 오프셋 초기화, 오프셋 커밋등을 담당합니다. 또한 Consumer Group의 상태를 관리하고, 누가 Consumer Leader인지 확인할 수 있습니다.

#### HeartBeatThread의 역할

- HeartBeatThread는 Consumer가 처음 poll 메서드를 호출할 때 ConsumerCoordinator에 의해 생성되고, 백그라운드로 동작하며, 주기적으로 자신의 상태를 Group Coordinator에게 알려줍니다.

<br>

## Consumer의 다양한 메서드

#### poll 메서드에 대해

```java
ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000L));
```

과정

1. 여러 consumer에서 첫 poll 메서드를 호출합니다.
2. poll 요청을 받은 브로커 중에서 하나의 브로커에서 Group Coordinator를 생성하고, 컨슈머에게 응답을 보내게 됩니다.
3. Consumer Group에 있는 여러 Consumer가 Group Coordinator에게 Join Group을 요청합니다.
4. Group Coordinator는 가장 먼저 요청을 보낸 Consumer가 Group Leader로 지정하고 응답을 보냅니다.
5. 가장 먼저 Join Group을 보낸 Consumer가 Leader Consumer가 됩니다.
6. Leader Consumer는 파티션 할당 전략에 따라 Consumer에게 파티션을 할당합니다.
7. Leader Consumer는 최종 할당된 파티션 정보를 Group Coordinator에게 전달합니다.
8. Group Coordinator는 해당 정보를 캐시하고, Consumer들에게 성공을 알립니다.
9. Consumer들은 이제 각자 지정된 토픽의 파티션으로부터 레코드를 가져옵니다.

<img width="1033" alt="스크린샷 2024-02-12 오후 4 13 59" src="https://github.com/kdg0209/realizers/assets/80187200/47cca862-85a3-4aae-aca8-7df101b64e0b">

<br>

#### commit 메서드에 대해

- consumer는 레코드를 읽은 뒤 commit 메서드를 통해 offset 정보를 브로커의 내부 토픽인 __consumer_offset에 기록합니다.
- __consumer_offset 토픽에 기록된 정보를 토대로 리밸런싱 등 consumer group에 변경이 발생하는 경우 해당 consumer가 어느 위치까지 레코드를 읽었는지 추적할 수 있습니다.
- __consumer_offset에 저장되는 offset은 consumer가 마지막까지 읽은 위치가 아니라 다음으로 읽어야 할 위치를 말합니다.

<br>

## Consumer의 다양한 commit 방법

#### Auto Commit

- enable.auto.commit: true
- auto.commit.interval.ms: 5000(5초)
- 위 옵션을 통해 Consumer가 Broker로부터 레코드를 읽어 바로 commit하지 않고 5초마다 Consumer가 자동적으로 commmit을 수행합니다.
- commit은 배치 단위로 처리됩니다.
- Consumer의 장애/재기동으로 인한 리밸런싱 후 Broker에서 이미 읽은 레코드를 다시 읽어와 중복 처리가 될 수 있습니다.
  - 예를들어 5~10번까지 읽어온 후 다음 poll 메서드를 수행할때 10번을 commit 하려는 순간 consumer에 장애가 발생하는 경우
    __consumer_offset은 commit offset을 받지 못하였기 때문에 리밸런싱 이후 다른 consumer는 5번을 다시 읽게 됩니다.

#### Sync Commit

- commitSync 메서드를 사용하면 commit을 보낼때 다음 poll 메서드는 blocking됩니다.
- commit에 실패하면 retry를 하다가 더 이상 재시도를 할 수 없는 경우 CommitFailedException이 발생합니다.

<img width="1026" alt="스크린샷 2024-02-12 오후 5 10 01" src="https://github.com/kdg0209/realizers/assets/80187200/83cb2fcd-0abc-426c-9c05-153394a585e1">

<br>

```java
public class Consumer {

    private static final Logger LOGGER = LoggerFactory.getLogger(Consumer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092, localhost:9093, localhost:9094";
    private static final String GROUP_NAME = "topic-C-group";
    private static final String TOPIC_NAME = "topic-C";

    public static void main(String[] args) {

        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, GROUP_NAME);
        properties.setProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        consumer.subscribe(List.of(TOPIC_NAME));

        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000L));
                for (ConsumerRecord<String, String> record : records) {
                    LOGGER.info("topic: {}, partition: {}, offset: {}, key: {}, value: {}", record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }

                try {
                    consumer.commitSync(); // 동기 커밋
                } catch (CommitFailedException e) {
                    e.printStackTrace();
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            consumer.close();
        }
    }
}
```

<br>

#### Async Commit

- 레코드를 poll 메서드를 통해 읽어온 뒤 레코드들의 마지막 offset을 브로커에게 commit 요청을 보내지만 브로커에 commit이 정상적으로 commit되었는지 확인하지 않고 계속하여 poll 메서드를 수행합니다.
- 브로커에 commit이 실패하더라도 commit을 재시도하지 않습니다. 그렇기 때문에 리밸런싱으로 인해 한번 읽은 레코드를 다시 읽을 수 있습니다.
- 에러가 발생하면 callback을 통해 로그를 남길 수 있습니다.

<img width="1026" alt="스크린샷 2024-02-12 오후 5 18 00" src="https://github.com/kdg0209/realizers/assets/80187200/2bf3ffb7-ef81-4dc3-8313-a42ff3e82f83">

```java
public class Consumer {

    private static final Logger LOGGER = LoggerFactory.getLogger(Consumer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092, localhost:9093, localhost:9094";
    private static final String GROUP_NAME = "topic-C-group";
    private static final String TOPIC_NAME = "topic-C";

    public static void main(String[] args) {

        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, GROUP_NAME);
        properties.setProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        consumer.subscribe(List.of(TOPIC_NAME));

        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000L));
                for (ConsumerRecord<String, String> record : records) {
                    LOGGER.info("topic: {}, partition: {}, offset: {}, key: {}, value: {}", record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }

                consumer.commitAsync((offsets, exception) -> {
                    if (exception != null) {
                        LOGGER.error("offsets: {} is not completed, error: {}", offsets, exception);
                    } else {
                        // ...
                    }
                });

            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            consumer.close();
        }
    }
}
```








