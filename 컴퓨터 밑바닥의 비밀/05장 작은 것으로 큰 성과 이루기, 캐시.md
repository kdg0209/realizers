[# 작은 것으로 큰 성과 이루기, 캐시

<br>

## 1. 캐시, 어디에나 존재하는 것

#### CPU와 메모리의 속도 차이

- 시스템의 성능은 속도가 상대적으로 느린 쪽에 맞추어 제한되므로 CPU와 메모리의 속도가 같아야 좋은 성능을 발휘할 수 있다는 나무통 원리를 만족합니다.
- 속도가 빠른 CPU는 명령어를 처리할 때 어쩔 수 없이 느릿느릿한 메모리를 기다리고 있을 수 밖에 없습니다.

#### L1 ,L2, L3 캐시

- L1 캐시의 접근 속도는 레지스터에 접근하는 속도에 비해 조금 느립니다. 4클럭 주기가 소요됩니다.
- L2 캐시의 접근 속도는 대략 10클럭 주기가 소요됩니다.
- L3 캐시의 접근 속도는 대략 50클럭 주기가 소요됩니다.
- 캐시 단계에 따라 접근 속도는 낮아지지만 그만큼 저장 공간은 많아집니다.
- L1, L2, L3, CPU는 레지스터 칩 내에 묶여 패키징되어 있습니다.

![스크린샷 2024-11-04 오후 9 37 17](https://github.com/user-attachments/assets/48a231a8-9179-4f5f-9599-8dd4a162eb33)

<br>

#### 캐시 갱신

- 캐시를 사용하면 메모리나 디스크로부터 데이터를 읽는 시간을 단축시킬 수 있으므로 성능은 개선되지만 캐시 데이터를 언제, 어떻게 메모리나 디스크에 갱신해야하는가?에 대한 문제가 발생합니다.
- 다중 코어를 사용하는 경우 데이터 불일치 문제가 발생할 수 있습니다. 따라서 각 코어간에 있는 캐시도 함께 갱신을 해줘야 합니다.

#### 페이지 캐시

- 컴퓨터 시스템의 메모리 사용률은 일반적으로 100%에 도달하지 않으며, 항상 일부 공간이 남아있습니다. 이 남은 공간을 헛되이 할 수 없으므로 운영체제는 이 여유 메모리 공간을 디스크의 캐시로 활용하여 디스크에서 데이터를 읽어오는 일을 최소화합니다.
- 리눅스는 파일 I/O의 성능을 향상시키기 위해 페이지 캐시라는 영역을 만들어서 사용하고 있습니다. 페이지 캐시 영역은 파일 I/O의 작업을 줄이기 위해서 있는 메모리 영역입니다.
- 한 번 읽은 파일의 내용을 페이지 캐시라는 영역에 저장시켜 놨다가 다시 한번 파일 I/O가 발생했을 때 디스크에서 읽지 않고 페이지 캐시에서 읽어서 데이터를 제공해주는 방식입니다.

![스크린샷 2024-11-04 오후 10 16 13](https://github.com/user-attachments/assets/f7c134ef-1d02-4b1e-9126-6e987b040c11)

<br>

## 2. 어떻게 캐시 친화적인 프로그램을 작성할까?

#### 시간적 지역성

- 시간적 지역성은 캐시 친화성이 매우 높은데, 이는 데이터가 캐시에 있는 한 메모리에 접근하지 않아도 반복적으로 캐시 적중이 가능하다는 의미입니다.

#### 공간적 지역성

- CPU가 메모리를 참조할 때 해당 메모리의 인접한 메모리도 참조할 수 있는데, 이를 공간적 지역성이라 합니다.
- 캐시가 적중하지 않으면 메모리의 데이터를 캐시에 적재해야 하는데, 이때 인접한 메모리의 주변 데이터도 함께 캐시에 저장합니다.

#### 캐시 친화적인 데이터 구조

- 지역성 원칙 관점에서는 배열이 연결 리스트보다 낫습니다. 그 이유는 배열은 하나의 연속된 메모리 공간을 할당 받지만 연결 리스트는 일반적으로 이곳저곳에 흩어져 있을 수 있기 때문입니다.
- 실제 데이터 구조를 사용할 때는 구체적인 상황에 맞추어 데이터 구조를 선택해야 합니다. 배열의 공간적 지역성은 연결 리스트의 공간적 지역성보다는 낫지만 상황에 따라 데이터가 빈번히 추가되고 삭제될 때는 연결 리스트의 시간 복잡도가 훨씬 빠릅니다.

<br>

## 3. 다중 스레드 성능 방해자

#### 캐시 라인

- 공간적 지역성의 원리는 CPU가 데이터를 읽기 위해 메모리에 접근하면 다음에는 해당 데이터와 인접한 데이터에 접근할 가능성이 높기 때문에 처음 데이터를 읽을 때 해당 데이터 주변에 있는 데이터도 함께 캐시에 적재하게 됩니다. 이때 주변 데이터도 함께 가져오는 것을 "묶음"이라 합니다.
- 캐시 라인의 기본적인 데이터 크기는 64바이트입니다.

#### 캐시 라인: 직접 매핑

- 직접 매핑은 메인 메모리를 일정한 크기의 블록으로 나눠 각각의 블록을 캐시의 정해진 위치에 매핑하는 방식입니다. 구현이 가장 간단하지만 캐시 적즁률이 낮아질 수 있습니다.

#### 캐시 라인: 연관 매핑

- 순서를 일치시키지 않고, 필요한 메모리 값을 캐시의 어디든 편하게 저장하는 방식입니다.
- 찾는 과정은 복잡하고 느리지만 필요한 캐시 위주로 저장하기에 적중률이 높습니다. 캐시는 일반 메모리보다 속도가 빠르므로 캐시의 접근 속도보다는 적중률에 신경을 써야합니다.

#### 캐시 거짓 공유

- 거짓 공유는 실제로 스레드 간 공유히지 않는 데이터이지만 캐시 구조의 특성으로 인해 마치 공유되는 것처럼 인식되어 불필요한 성능 저하가 발생하는 것입니다.
- 다중 프로그래밍을 할 때 동일한 캐시 라인 내에 있는 서로 다른 위치의 데이터를 참조할 때 거짓 공유가 발생합니다.
- 실제 같은 데이터를 참조하지 않는 상황에도 불구하고 캐시 일관성을 유지하기 위해 발생하는 현상입니다.

참고

- https://jay-choe.tistory.com/12










