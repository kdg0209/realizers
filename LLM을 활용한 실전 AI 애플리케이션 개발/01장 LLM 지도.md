# LLM 지도

- LLM 언어 모델은 주어진 입력에서 다음에 올 적절한 단어를 확률적으로 선택(`예측`)하고, 문장을 하나씩 만들어 가는 방식으로 텍스트를 생성합니다.

<br>

## 1. 딥러닝과 언어 모델링

- LLM은 기술적으로 딥러닝에 기반을 두고 있으며, `딥러닝`이란 인간의 두뇌에서 영감을 받아 만들어진 신경망으로서 데이터의 패턴을 학습하는 머신러닝의 한 분야입니다.
- 딥러닝 기반의 언어 모델이 탄생하기까지 중요했던 사건이 있는데, `워드투백`과 `트랜스포머 아키텍처`가 있습니다.

### 1-1. 머신러닝과 딥러닝의 차이

- 데이터의 특징을 누가 뽑는가? 가 가장 큰 차이점입니다.

#### 머신러닝

- 머신러닝은 사람이 입력값에서 데이터의 특징을 추출하고 모델에 입력으로 넣어 결과를 추출하는 것입니다.

#### 딥러닝

- 딥러닝은 학습 과정에서 데이터의 특징을 추출하는 방법도 함께 배우고 이를 결과로 도출합니다.

<img width="1032" alt="스크린샷 2025-05-24 오후 12 42 10" src="https://github.com/user-attachments/assets/11220062-1bb6-4a59-a062-8d7425fc3b96" />

<br><br>

### 1-2. 임베딩이란 무엇인가?

#### 💡 임베딩이란?

- `임베딩`은 데이터의 의미와 특징을 포착해 숫자로 표현한 것입니다.
- 단어, 문장, 문서, 이미지, 비디오 등의 비정형 데이터를 고정된 크기의 벡터로 표현하는 기법입니다. 이러한 벡터들은 보통 실수(float)값을 가지고 있습니다.
- 2013년 구글의 Mikolov 팀에서 `Word2Vec`이라는 자연어를 벡터 공간에 매핑하는 기초적인 방식을 제공하였습니다.

#### 예시

- 임베딩을 사용하면 유사한 단어끼리 비슷한 벡터값을 가질 수 있습니다.
- 임베딩을 활용하면 거리를 계산할 수 있기 때문에 검색 및 추천, 클러스터링 및 분류 등 다양한 작업에 사용될 수 있습니다.

```txt
["강아지", "고양이", "사자", "자동차", "비행기"]

> 임베딩 벡터(3차원 예시)
강아지: [0.9, 0.2, 0.1]
고양이: [0.92, 0.18, 0.15]
사자: [0.7, 0.1, 0.2]
자동차: [-0.8, 0.5, 0.9]
비행기: [-0.85, 0.55, 0.95]
```

<br>

### 1-3. 언어 모델링이란 무엇인가?

#### 💡 언어 모델링이란?

- `언어 모델링`이란 모델이 입력받은 텍스트의 다음 단어를 예측해 텍스트를 생성하는 방법을 말합니다.

#### 사전 학습(Pretraining)

- 대규모 데이터로 일반적인 언어 능력을 먼저 학습하는 단계입니다.
- 빈칸 채우기, 다음 단어 예측 등 모델이 아무것도 모를 때 사용된다고 합니다.

#### 전이 학습(Transfer Learning)

- 사전 학습된 모델의 지식을 재사용하여 새로운 작업에 적용하는 것입니다.

#### 미세 조정(Fine-tuning)

- 전이된 모델을 특정 태스크(분류, QA 등)에 맞춰 추가로 훈련시키는 것입니다.
- 사전 학습된 모델을 특정 업무에 최적화시키고 싶은 경우에 사용된다고 합니다.

<br>

## 2. RNN에서 트랜스포머 아키텍처로

- 딥러닝이나 머신러낭에서 텍스트는 단어가 연결된 문장 형태의 데이터를 말합니다. 작은 단위(단어)의 데이터가 연결되고, 그 길이가 다양한 데이터의 형태를 `시퀀스`라 합니다.

### 2-1. RNN이란?

- `RNN`은 과거의 정보를 현재의 입력과 함께 처리하는 신경망입니다.
- 즉, 입력하는 텍스트를 `순차적`으로 처리해서 다음 단어를 예측하게 됩니다.
- RNN에서는 `은닉 상태`라는 개념이 있는데, `은닉 상태`는 이전 입력에 대한 정보를 압축하여 다음으로 넘겨주는 역할을 수행합니다.
 
#### 🚗 동작 원리

- `RNN`은 입력 시퀀스를 한 단계씩 순서대로 처리하고, 이전 단계의 출력을 기억하고 다음 단계로 전달하게 됩니다.
- 이 과정은 순차적이고, 단어를 하나의 `은닉 상태`로 압축하다 보니 먼저 입력한 단어의 의미가 점차 희석되는 문제가 발생하게 됩니다.

<img width="1032" alt="스크린샷 2025-05-24 오후 1 43 43" src="https://github.com/user-attachments/assets/fa7be4c9-6c19-4e9b-ab0a-e7a897994988" />

<br><br>

### 2-2. 트랜스포머 아키텍처란?
ㅌ
- 2017년 등장한 `트랜스포머 아키텍처`는 RNN의 순차적인 처리 방식을 버리고 맥락을 모두 참조하는 `어텐션`연산을 사용합니다.
- 아... 벌써 너무 어렵다.....

#### 🚗 동작 원리

- `트랜스포머 아키텍처` 병렬처리가 가능하기 때문에 모든 시점 간 관계를 동시에 학습하게 됩니다. RNN은 순차적으로 처리했기 때문에 긴 문맥에 약했지만 `트랜스포머 아키텍처`는 긴 문맥에 대해서도 수준급으로 잘 처리할 수 있게 되었습니다.
- 모든 단어를 직접 참조(`Self-Attention`) 하기 때문에 과거, 현재, 미래 단어 모두와 연결할 수 있습니다.

<img width="1032" alt="스크린샷 2025-05-24 오후 2 00 45" src="https://github.com/user-attachments/assets/2940bba5-b7be-4f10-bf61-1a2bbc1e5e15" />


